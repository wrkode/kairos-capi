/*
Copyright 2024 The Kairos CAPI Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
implied. See the License for the specific language governing
permissions and limitations under the License.
*/

package bootstrap

import (
	"context"
	"crypto/rand"
	"encoding/base64"
	"fmt"
	"strings"
	"time"

	"github.com/go-logr/logr"
	corev1 "k8s.io/api/core/v1"
	apierrors "k8s.io/apimachinery/pkg/api/errors"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured"
	"k8s.io/apimachinery/pkg/runtime"
	"k8s.io/apimachinery/pkg/runtime/schema"
	"k8s.io/apimachinery/pkg/types"
	clusterv1 "sigs.k8s.io/cluster-api/api/v1beta1"
	"sigs.k8s.io/cluster-api/util"
	"sigs.k8s.io/cluster-api/util/conditions"
	"sigs.k8s.io/cluster-api/util/patch"
	ctrl "sigs.k8s.io/controller-runtime"
	"sigs.k8s.io/controller-runtime/pkg/client"
	"sigs.k8s.io/controller-runtime/pkg/controller/controllerutil"
	"sigs.k8s.io/controller-runtime/pkg/handler"
	"sigs.k8s.io/controller-runtime/pkg/reconcile"

	bootstrapv1beta2 "github.com/wrkode/kairos-capi/api/bootstrap/v1beta2"
	"github.com/wrkode/kairos-capi/internal/bootstrap"
)

// KairosConfigReconciler reconciles a KairosConfig object
type KairosConfigReconciler struct {
	client.Client
	Scheme *runtime.Scheme
}

//+kubebuilder:rbac:groups=bootstrap.cluster.x-k8s.io,resources=kairosconfigs,verbs=get;list;watch;create;update;patch;delete
//+kubebuilder:rbac:groups=bootstrap.cluster.x-k8s.io,resources=kairosconfigs/status,verbs=get;update;patch
//+kubebuilder:rbac:groups=bootstrap.cluster.x-k8s.io,resources=kairosconfigs/finalizers,verbs=update
//+kubebuilder:rbac:groups=cluster.x-k8s.io,resources=machines;clusters,verbs=get;list;watch
//+kubebuilder:rbac:groups=cluster.x-k8s.io,resources=machines/status;clusters/status,verbs=get;update;patch
//+kubebuilder:rbac:groups=infrastructure.cluster.x-k8s.io,resources=vspheremachines,verbs=get;list;watch
//+kubebuilder:rbac:groups=infrastructure.cluster.x-k8s.io,resources=vspheremachines/status,verbs=get
//+kubebuilder:rbac:groups="",resources=secrets;events,verbs=get;list;watch;create;update;patch;delete
//+kubebuilder:rbac:groups="",resources=configmaps,verbs=get;list;watch
//+kubebuilder:rbac:groups=coordination.k8s.io,resources=leases,verbs=create;get;list;update;patch;watch
//+kubebuilder:rbac:groups=cert-manager.io,resources=certificates,verbs=get;list;watch
//+kubebuilder:rbac:groups=admissionregistration.k8s.io,resources=mutatingwebhookconfigurations;validatingwebhookconfigurations,verbs=get;list;patch;update
//+kubebuilder:rbac:groups=batch,resources=jobs,verbs=create;get;list;watch
//+kubebuilder:rbac:groups=apps,resources=deployments,verbs=get;list;patch;update

// Reconcile is part of the main kubernetes reconciliation loop
func (r *KairosConfigReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
	log := ctrl.LoggerFrom(ctx)

	// Fetch the KairosConfig instance
	kairosConfig := &bootstrapv1beta2.KairosConfig{}
	if err := r.Get(ctx, req.NamespacedName, kairosConfig); err != nil {
		if apierrors.IsNotFound(err) {
			return ctrl.Result{}, nil
		}
		return ctrl.Result{}, err
	}

	// Handle deletion
	if !kairosConfig.ObjectMeta.DeletionTimestamp.IsZero() {
		return r.reconcileDelete(ctx, log, kairosConfig)
	}

	// Add finalizer if needed
	if !controllerutil.ContainsFinalizer(kairosConfig, bootstrapv1beta2.KairosConfigFinalizer) {
		controllerutil.AddFinalizer(kairosConfig, bootstrapv1beta2.KairosConfigFinalizer)
		if err := r.Update(ctx, kairosConfig); err != nil {
			return ctrl.Result{}, err
		}
	}

	// Check if paused
	if kairosConfig.Spec.Pause {
		log.Info("KairosConfig is paused, skipping reconciliation")
		return ctrl.Result{}, nil
	}

	// Find the owning Machine
	machine, err := util.GetOwnerMachine(ctx, r.Client, kairosConfig.ObjectMeta)
	if err != nil {
		log.Error(err, "Failed to get owner machine")
		return ctrl.Result{}, err
	}
	if machine == nil {
		log.Info("Machine Controller has not yet set OwnerRef")
		return ctrl.Result{}, nil
	}

	// Find the owning Cluster
	cluster, err := util.GetClusterFromMetadata(ctx, r.Client, machine.ObjectMeta)
	if err != nil {
		log.Error(err, "Failed to get cluster from machine metadata")
		return ctrl.Result{}, err
	}
	if cluster == nil {
		log.Info("Cluster is not available yet")
		return ctrl.Result{}, nil
	}

	// Initialize patch helper
	helper, err := patch.NewHelper(kairosConfig, r.Client)
	if err != nil {
		return ctrl.Result{}, err
	}

	// Always update observedGeneration
	kairosConfig.Status.ObservedGeneration = kairosConfig.Generation

	// Reconcile bootstrap data
	result, err := r.reconcileBootstrapData(ctx, log, kairosConfig, machine, cluster)
	if err != nil {
		// Mark conditions as false on error
		// Use "%s" as format string and pass error as argument to satisfy linter
		conditions.MarkFalse(kairosConfig, clusterv1.ReadyCondition, bootstrapv1beta2.BootstrapDataSecretGenerationFailedReason, clusterv1.ConditionSeverityWarning, "%s", err.Error())
		conditions.MarkFalse(kairosConfig, bootstrapv1beta2.BootstrapReadyCondition, bootstrapv1beta2.BootstrapDataSecretGenerationFailedReason, clusterv1.ConditionSeverityWarning, "%s", err.Error())
		conditions.MarkFalse(kairosConfig, bootstrapv1beta2.DataSecretAvailableCondition, bootstrapv1beta2.BootstrapDataSecretGenerationFailedReason, clusterv1.ConditionSeverityWarning, "%s", err.Error())

		kairosConfig.Status.FailureReason = bootstrapv1beta2.BootstrapDataSecretGenerationFailedReason
		kairosConfig.Status.FailureMessage = err.Error()
		kairosConfig.Status.Ready = false

		return ctrl.Result{}, helper.Patch(ctx, kairosConfig)
	}

	// If reconcileBootstrapData requested a requeue (e.g., waiting for providerID), return it
	if result.Requeue || result.RequeueAfter > 0 {
		return result, helper.Patch(ctx, kairosConfig)
	}

	// Mark conditions as true on success
	conditions.MarkTrue(kairosConfig, clusterv1.ReadyCondition)
	conditions.MarkTrue(kairosConfig, bootstrapv1beta2.BootstrapReadyCondition)
	conditions.MarkTrue(kairosConfig, bootstrapv1beta2.DataSecretAvailableCondition)

	// Clear failure fields
	kairosConfig.Status.FailureReason = ""
	kairosConfig.Status.FailureMessage = ""

	// Update status
	return ctrl.Result{}, helper.Patch(ctx, kairosConfig)
}

func (r *KairosConfigReconciler) reconcileBootstrapData(ctx context.Context, log logr.Logger, kairosConfig *bootstrapv1beta2.KairosConfig, machine *clusterv1.Machine, cluster *clusterv1.Cluster) (ctrl.Result, error) {
	// Get providerID - it may not be available initially (before VM is created)
	// We allow bootstrap secret creation without providerID initially, then regenerate when providerID becomes available
	currentProviderID := r.getProviderID(ctx, log, machine)

	// For VSphere: Only wait for providerID if VSphereMachine is Ready (VM already provisioned)
	// If VSphereMachine is not Ready yet, allow secret creation so VM can be provisioned
	// This avoids circular dependency: VM needs bootstrap secret to be created, but providerID is set after VM creation
	if machine != nil && machine.Spec.InfrastructureRef.Kind == "VSphereMachine" && currentProviderID == "" {
		vsphereMachine := &unstructured.Unstructured{}
		vsphereMachine.SetGroupVersionKind(schema.GroupVersionKind{
			Group:   "infrastructure.cluster.x-k8s.io",
			Version: "v1beta1",
			Kind:    "VSphereMachine",
		})
		vsphereMachineKey := types.NamespacedName{
			Name:      machine.Spec.InfrastructureRef.Name,
			Namespace: machine.Spec.InfrastructureRef.Namespace,
		}

		if err := r.Get(ctx, vsphereMachineKey, vsphereMachine); err == nil {
			// Check if VSphereMachine is Ready (VM provisioned)
			// Look for Ready condition in status.conditions array
			conditions, found, _ := unstructured.NestedSlice(vsphereMachine.Object, "status", "conditions")
			isReady := false
			if found {
				for _, cond := range conditions {
					condMap, ok := cond.(map[string]interface{})
					if ok {
						condType, _ := condMap["type"].(string)
						condStatus, _ := condMap["status"].(string)
						if condType == "Ready" && condStatus == "True" {
							isReady = true
							break
						}
					}
				}
			}

			// Only wait for providerID if VM is already Ready (provisioned)
			// If VM is not Ready yet, proceed with secret creation (VM needs bootstrap secret to be created first)
			if isReady {
				log.V(4).Info("VSphereMachine is Ready but providerID not yet set, waiting briefly for CAPV to set it",
					"machine", machine.Name,
					"vsphereMachine", vsphereMachineKey.Name)
				return ctrl.Result{RequeueAfter: 5 * time.Second}, nil
			}
			// If VM is not Ready yet, proceed with secret creation - this allows VM to be provisioned
			log.V(5).Info("VSphereMachine not Ready yet, proceeding with bootstrap secret creation",
				"machine", machine.Name,
				"vsphereMachine", vsphereMachineKey.Name)
		}
	}

	// If dataSecretName is already set, verify the secret exists and check if regeneration is needed
	if kairosConfig.Status.DataSecretName != nil {
		secret := &corev1.Secret{}
		secretKey := types.NamespacedName{
			Name:      *kairosConfig.Status.DataSecretName,
			Namespace: kairosConfig.Namespace,
		}
		if err := r.Get(ctx, secretKey, secret); err != nil {
			if apierrors.IsNotFound(err) {
				// Secret was deleted, regenerate
				log.Info("Bootstrap secret was deleted, regenerating", "secret", *kairosConfig.Status.DataSecretName)
				kairosConfig.Status.DataSecretName = nil
			} else {
				return ctrl.Result{}, fmt.Errorf("failed to get bootstrap secret: %w", err)
			}
		} else {
			// Secret exists, check if we need to regenerate it due to providerID availability
			needsRegeneration := false
			currentProviderID := r.getProviderID(ctx, log, machine)

			if currentProviderID != "" {
				// Machine has providerID, check if the secret contains it
				secretData, ok := secret.Data["value"]
				if !ok {
					log.Info("Bootstrap secret missing data, regenerating", "secret", *kairosConfig.Status.DataSecretName)
					needsRegeneration = true
				} else {
					// Kubernetes secrets store data as base64-encoded strings
					// Decode once to get the plain cloud-config YAML
					decodedData, err := base64.StdEncoding.DecodeString(string(secretData))
					if err != nil {
						log.Info("Failed to decode bootstrap secret, regenerating", "secret", *kairosConfig.Status.DataSecretName, "error", err)
						needsRegeneration = true
					} else {
						// Check if the decoded cloud-config contains the providerID in the systemd service script
						cloudConfigStr := string(decodedData)
						// Check if providerID is present in the script
						hasProviderIDInSecret := strings.Contains(cloudConfigStr, currentProviderID)

						// Check if there's a k0s post-bootstrap service (indicating providerID was included)
						// If Machine has providerID but secret has no service, we need to regenerate
						hasK0sPostBootstrapService := strings.Contains(cloudConfigStr, "kairos-k0s-post-bootstrap.service")

						if currentProviderID != "" && (!hasProviderIDInSecret || !hasK0sPostBootstrapService) {
							log.Info("Bootstrap secret missing providerID in k0s post-bootstrap service, regenerating to include it",
								"secret", *kairosConfig.Status.DataSecretName,
								"providerID", currentProviderID,
								"hasProviderIDInSecret", hasProviderIDInSecret,
								"hasK0sPostBootstrapService", hasK0sPostBootstrapService)
							needsRegeneration = true
						}
					}
				}
			}

			if needsRegeneration {
				// Keep the existing secret name and regenerate its contents.
				// The Machine's bootstrap dataSecretName is immutable, so we must not change it.
				log.Info("Bootstrap secret needs regeneration; will update existing secret",
					"secret", *kairosConfig.Status.DataSecretName)
			} else {
				// Secret exists and is up-to-date, verify it's ready
				log.V(4).Info("Bootstrap data already generated and up-to-date", "secret", *kairosConfig.Status.DataSecretName)
				kairosConfig.Status.Ready = true
				// Ensure initialization.dataSecretCreated is set
				if kairosConfig.Status.Initialization == nil {
					kairosConfig.Status.Initialization = &bootstrapv1beta2.KairosConfigInitialization{}
				}
				kairosConfig.Status.Initialization.DataSecretCreated = true
				return ctrl.Result{}, nil
			}
		}
	}

	// Generate Kairos cloud-config
	cloudConfig, err := r.generateCloudConfig(ctx, log, kairosConfig, machine, cluster)
	if err != nil {
		return ctrl.Result{}, fmt.Errorf("failed to generate cloud-config: %w", err)
	}

	// Store the cloud-config as plain text in the secret
	// Kubernetes will automatically base64 encode it when storing in etcd
	// CAPV will read it, base64 decode it (removing Kubernetes encoding), and get plain text
	// CAPV will then pass it to VMware guestinfo properties as userdata (and possibly vendordata)
	// Note: There is a known issue where CAPV may set vendordata without setting guestinfo.vendordata.encoding,
	// which causes Kairos to log "VMWare: Failed to get vendordata: Unknown encoding". However, userdata works
	// correctly, so this error is non-blocking and the cluster will function properly.
	// Do NOT base64 encode it ourselves - let CAPV handle the encoding

	// Create Secret with bootstrap data
	secretName := ""
	if kairosConfig.Status.DataSecretName != nil {
		secretName = *kairosConfig.Status.DataSecretName
	} else {
		randomSuffix, err := randomString(6)
		if err != nil {
			return ctrl.Result{}, fmt.Errorf("failed to generate random string: %w", err)
		}
		secretName = fmt.Sprintf("%s-%s", kairosConfig.Name, randomSuffix)
	}

	secretKey := types.NamespacedName{
		Name:      secretName,
		Namespace: kairosConfig.Namespace,
	}
	secret := &corev1.Secret{
		ObjectMeta: metav1.ObjectMeta{
			Name:      secretName,
			Namespace: kairosConfig.Namespace,
			Labels: map[string]string{
				clusterv1.ClusterNameLabel: cluster.Name,
			},
			OwnerReferences: []metav1.OwnerReference{
				{
					APIVersion: kairosConfig.APIVersion,
					Kind:       kairosConfig.Kind,
					Name:       kairosConfig.Name,
					UID:        kairosConfig.UID,
					Controller: func() *bool { b := true; return &b }(),
				},
			},
		},
		Type: clusterv1.ClusterSecretType,
		Data: map[string][]byte{
			"value": []byte(cloudConfig),
		},
	}

	// Create or update the secret in-place to preserve the name referenced by Machine
	existingSecret := &corev1.Secret{}
	if err := r.Get(ctx, secretKey, existingSecret); err != nil {
		if apierrors.IsNotFound(err) {
			if err := r.Create(ctx, secret); err != nil {
				return ctrl.Result{}, err
			}
		} else {
			return ctrl.Result{}, err
		}
	} else {
		existingSecret.Type = secret.Type
		existingSecret.Labels = secret.Labels
		existingSecret.OwnerReferences = secret.OwnerReferences
		existingSecret.Data = secret.Data
		if err := r.Update(ctx, existingSecret); err != nil {
			return ctrl.Result{}, err
		}
	}

	// Update status with dataSecretName
	kairosConfig.Status.DataSecretName = &secretName

	// Mark secret as Ready - providerID will be included if available, otherwise it will be regenerated later
	// We allow the secret to be Ready even without providerID initially, so VM can be created
	// When providerID becomes available (via VSphereMachine watch), the secret will be regenerated
	if currentProviderID != "" {
		// Verify providerID is included in the cloud-config
		// cloudConfig is plain text, no need to decode
		hasProviderIDInSecret := strings.Contains(cloudConfig, currentProviderID)
		// Check for the systemd service that sets providerID (runs after k0s.service starts)
		hasK0sPostBootstrapService := strings.Contains(cloudConfig, "kairos-k0s-post-bootstrap.service")

		if hasProviderIDInSecret && hasK0sPostBootstrapService {
			kairosConfig.Status.Ready = true
			log.Info("Bootstrap data secret created with providerID", "secret", secretName, "providerID", currentProviderID)
		} else {
			// ProviderID should be included but wasn't - regenerate
			log.Info("Bootstrap secret created but providerID not properly included, will regenerate",
				"secret", secretName,
				"providerID", currentProviderID,
				"hasProviderID", hasProviderIDInSecret,
				"hasK0sPostBootstrapService", hasK0sPostBootstrapService)
			kairosConfig.Status.Ready = false
			return ctrl.Result{RequeueAfter: 5 * time.Second}, nil
		}
	} else {
		// No providerID available yet - mark as Ready so VM can be created
		// When providerID becomes available (via VSphereMachine watch), secret will be regenerated
		kairosConfig.Status.Ready = true
		log.Info("Bootstrap secret created without providerID (will be regenerated when providerID becomes available)",
			"secret", secretName)
	}

	// Set initialization.dataSecretCreated as required by Cluster API contract
	// This field is used by the Machine controller to determine when bootstrap data is ready
	if kairosConfig.Status.Initialization == nil {
		kairosConfig.Status.Initialization = &bootstrapv1beta2.KairosConfigInitialization{}
	}
	kairosConfig.Status.Initialization.DataSecretCreated = true

	return ctrl.Result{}, nil
}

func (r *KairosConfigReconciler) generateCloudConfig(ctx context.Context, log logr.Logger, kairosConfig *bootstrapv1beta2.KairosConfig, machine *clusterv1.Machine, cluster *clusterv1.Cluster) (string, error) {
	// Determine role
	role := kairosConfig.Spec.Role
	if role == "" {
		// Infer from machine labels
		if util.IsControlPlaneMachine(machine) {
			role = "control-plane"
		} else {
			role = "worker"
		}
	}

	// Determine distribution
	distribution := kairosConfig.Spec.Distribution
	if distribution == "" {
		distribution = "k0s"
	}

	// Get cluster information
	serverAddress := kairosConfig.Spec.ServerAddress
	if serverAddress == "" && cluster.Spec.ControlPlaneEndpoint.IsValid() {
		serverAddress = fmt.Sprintf("https://%s:%d", cluster.Spec.ControlPlaneEndpoint.Host, cluster.Spec.ControlPlaneEndpoint.Port)
	}

	// Generate cloud-config based on distribution
	switch distribution {
	case "k0s":
		return r.generateK0sCloudConfig(ctx, log, kairosConfig, machine, cluster, role, serverAddress)
	case "k3s":
		return "", fmt.Errorf("k3s distribution not yet implemented")
	default:
		return "", fmt.Errorf("unsupported distribution: %s", distribution)
	}
}

func (r *KairosConfigReconciler) generateK0sCloudConfig(ctx context.Context, log logr.Logger, kairosConfig *bootstrapv1beta2.KairosConfig, machine *clusterv1.Machine, cluster *clusterv1.Cluster, role, serverAddress string) (string, error) {
	// Determine single-node mode
	// Single-node is determined by:
	// 1. Explicit flag in KairosConfig.spec.singleNode
	// 2. Or if this is a control-plane and we can check the owning KairosControlPlane
	singleNode := kairosConfig.Spec.SingleNode
	if !singleNode && role == "control-plane" && machine != nil {
		// Try to find the owning KairosControlPlane to check replicas
		ownerRef := metav1.GetControllerOf(machine)
		if ownerRef != nil && ownerRef.Kind == "KairosControlPlane" {
			// For now, we rely on the SingleNode flag in spec
			// In the future, we could fetch the KCP and check spec.replicas == 1
			log.V(4).Info("Control plane node, single-node mode determined from spec", "singleNode", singleNode)
		}
	}

	// Get worker token if needed (for worker nodes)
	// Precedence: WorkerTokenSecretRef > WorkerToken > TokenSecretRef > Token
	// TODO: Add validating webhook to enforce worker token requirement at API level
	var workerToken string
	if role == "worker" {
		// Try WorkerTokenSecretRef first (most secure)
		if kairosConfig.Spec.WorkerTokenSecretRef != nil {
			secretKey := types.NamespacedName{
				Namespace: kairosConfig.Namespace,
				Name:      kairosConfig.Spec.WorkerTokenSecretRef.Name,
			}
			// Use specified namespace or fall back to KairosConfig namespace
			if kairosConfig.Spec.WorkerTokenSecretRef.Namespace != "" {
				secretKey.Namespace = kairosConfig.Spec.WorkerTokenSecretRef.Namespace
			}

			secret := &corev1.Secret{}
			if err := r.Get(ctx, secretKey, secret); err != nil {
				return "", fmt.Errorf("failed to get worker token secret %s/%s: %w", secretKey.Namespace, secretKey.Name, err)
			}

			// Use specified key or default to "token"
			key := kairosConfig.Spec.WorkerTokenSecretRef.Key
			if key == "" {
				key = "token"
			}

			if tokenData, ok := secret.Data[key]; ok {
				workerToken = string(tokenData)
			} else {
				return "", fmt.Errorf("worker token secret %s/%s does not contain key '%s'", secretKey.Namespace, secretKey.Name, key)
			}
		} else if kairosConfig.Spec.WorkerToken != "" {
			// Fall back to inline WorkerToken
			workerToken = kairosConfig.Spec.WorkerToken
		} else if kairosConfig.Spec.TokenSecretRef != nil {
			// Fall back to legacy TokenSecretRef
			secret := &corev1.Secret{}
			secretKey := types.NamespacedName{
				Namespace: cluster.Namespace,
				Name:      kairosConfig.Spec.TokenSecretRef.Name,
			}
			if err := r.Get(ctx, secretKey, secret); err != nil {
				return "", fmt.Errorf("failed to get token secret: %w", err)
			}
			// Try common token keys
			if tokenData, ok := secret.Data["token"]; ok {
				workerToken = string(tokenData)
			} else if tokenData, ok := secret.Data["value"]; ok {
				workerToken = string(tokenData)
			} else {
				return "", fmt.Errorf("token secret does not contain 'token' or 'value' key")
			}
		} else if kairosConfig.Spec.Token != "" {
			// Fall back to legacy Token
			workerToken = kairosConfig.Spec.Token
		}

		// Validate worker token is present
		if workerToken == "" {
			return "", fmt.Errorf("worker token is required for worker nodes: either WorkerTokenSecretRef, WorkerToken, TokenSecretRef, or Token must be set")
		}
	}

	// Set defaults for user configuration
	userName := kairosConfig.Spec.UserName
	if userName == "" {
		userName = "kairos"
	}
	userPassword := kairosConfig.Spec.UserPassword
	if userPassword == "" {
		userPassword = "kairos"
	}
	userGroups := kairosConfig.Spec.UserGroups
	if len(userGroups) == 0 {
		userGroups = []string{"admin"}
	}

	// Set hostname prefix (default to "metal-" if not specified)
	hostnamePrefix := kairosConfig.Spec.HostnamePrefix
	if hostnamePrefix == "" {
		hostnamePrefix = "metal-"
	}

	// Set install configuration (with defaults)
	var installConfig *bootstrap.InstallConfig
	if kairosConfig.Spec.Install != nil {
		installConfig = &bootstrap.InstallConfig{
			Auto:   true,   // Default to true
			Device: "auto", // Default to "auto"
			Reboot: true,   // Default to true
		}
		if kairosConfig.Spec.Install.Auto != nil {
			installConfig.Auto = *kairosConfig.Spec.Install.Auto
		}
		if kairosConfig.Spec.Install.Device != "" {
			installConfig.Device = kairosConfig.Spec.Install.Device
		}
		if kairosConfig.Spec.Install.Reboot != nil {
			installConfig.Reboot = *kairosConfig.Spec.Install.Reboot
		}
	}

	// Get providerID from Machine's infrastructure reference
	// This is needed to set the Node's providerID so the Machine controller can match Nodes to Machines
	providerID := r.getProviderID(ctx, log, machine)

	// Build template data
	templateData := bootstrap.TemplateData{
		Role:           role,
		SingleNode:     singleNode,
		UserName:       userName,
		UserPassword:   userPassword,
		UserGroups:     userGroups,
		GitHubUser:     kairosConfig.Spec.GitHubUser,
		SSHPublicKey:   kairosConfig.Spec.SSHPublicKey,
		WorkerToken:    workerToken,
		Manifests:      kairosConfig.Spec.Manifests,
		HostnamePrefix: hostnamePrefix,
		Install:        installConfig,
		ProviderID:     providerID,
	}

	// Render template
	return bootstrap.RenderK0sCloudConfig(templateData)
}

func (r *KairosConfigReconciler) reconcileDelete(ctx context.Context, log logr.Logger, kairosConfig *bootstrapv1beta2.KairosConfig) (ctrl.Result, error) {
	// Remove finalizer
	controllerutil.RemoveFinalizer(kairosConfig, bootstrapv1beta2.KairosConfigFinalizer)
	return ctrl.Result{}, r.Update(ctx, kairosConfig)
}

func splitLines(s string) []string {
	return strings.Split(s, "\n")
}

// randomString generates a random lowercase alphanumeric string of the given length
// This ensures the string is RFC 1123 compliant for Kubernetes resource names
func randomString(length int) (string, error) {
	const charset = "abcdefghijklmnopqrstuvwxyz0123456789"
	b := make([]byte, length)
	for i := range b {
		randomByte := make([]byte, 1)
		if _, err := rand.Read(randomByte); err != nil {
			return "", err
		}
		b[i] = charset[randomByte[0]%byte(len(charset))]
	}
	return string(b), nil
}

// SetupWithManager sets up the controller with the Manager.
func (r *KairosConfigReconciler) SetupWithManager(mgr ctrl.Manager) error {
	// Create unstructured VSphereMachine object for watching
	vsphereMachineGVK := schema.GroupVersionKind{
		Group:   "infrastructure.cluster.x-k8s.io",
		Version: "v1beta1",
		Kind:    "VSphereMachine",
	}
	vsphereMachine := &unstructured.Unstructured{}
	vsphereMachine.SetGroupVersionKind(vsphereMachineGVK)

	return ctrl.NewControllerManagedBy(mgr).
		For(&bootstrapv1beta2.KairosConfig{}).
		Watches(
			&clusterv1.Machine{},
			handler.EnqueueRequestsFromMapFunc(r.machineToKairosConfig),
		).
		Watches(
			vsphereMachine,
			handler.EnqueueRequestsFromMapFunc(r.vsphereMachineToKairosConfig),
		).
		Complete(r)
}

// machineToKairosConfig maps a Machine to its KairosConfig
func (r *KairosConfigReconciler) machineToKairosConfig(ctx context.Context, o client.Object) []reconcile.Request {
	machine, ok := o.(*clusterv1.Machine)
	if !ok {
		return nil
	}

	// Check if Machine has a bootstrap config reference
	if machine.Spec.Bootstrap.ConfigRef == nil {
		return nil
	}

	// Check if it's a KairosConfig
	if machine.Spec.Bootstrap.ConfigRef.GroupVersionKind().Group != bootstrapv1beta2.GroupVersion.Group {
		return nil
	}
	if machine.Spec.Bootstrap.ConfigRef.Kind != "KairosConfig" {
		return nil
	}

	return []reconcile.Request{
		{
			NamespacedName: types.NamespacedName{
				Name:      machine.Spec.Bootstrap.ConfigRef.Name,
				Namespace: machine.Namespace,
			},
		},
	}
}

// vsphereMachineToKairosConfig maps a VSphereMachine to its KairosConfig
// This allows us to watch for VSphereMachine changes (especially when providerID is set)
// and trigger KairosConfig reconciliation to regenerate bootstrap secret with providerID
func (r *KairosConfigReconciler) vsphereMachineToKairosConfig(ctx context.Context, o client.Object) []reconcile.Request {
	// Verify this is an unstructured object (VSphereMachine)
	if _, ok := o.(*unstructured.Unstructured); !ok {
		return nil
	}

	// Get the Machine that owns this VSphereMachine
	// VSphereMachine is typically owned by a Machine
	machineList := &clusterv1.MachineList{}
	if err := r.List(ctx, machineList, client.InNamespace(o.GetNamespace())); err != nil {
		return nil
	}

	var requests []reconcile.Request
	for _, machine := range machineList.Items {
		// Check if this Machine references the VSphereMachine
		if machine.Spec.InfrastructureRef.Kind == "VSphereMachine" &&
			machine.Spec.InfrastructureRef.Name == o.GetName() &&
			machine.Spec.InfrastructureRef.Namespace == o.GetNamespace() {
			// Check if Machine has a bootstrap config reference to KairosConfig
			if machine.Spec.Bootstrap.ConfigRef != nil &&
				machine.Spec.Bootstrap.ConfigRef.GroupVersionKind().Group == bootstrapv1beta2.GroupVersion.Group &&
				machine.Spec.Bootstrap.ConfigRef.Kind == "KairosConfig" {
				requests = append(requests, reconcile.Request{
					NamespacedName: types.NamespacedName{
						Name:      machine.Spec.Bootstrap.ConfigRef.Name,
						Namespace: machine.Spec.Bootstrap.ConfigRef.Namespace,
					},
				})
			}
		}
	}

	return requests
}

// getProviderID retrieves the providerID from the Machine's infrastructure reference
// This is used to configure k0s/kubelet to set the providerID on the Node
// so the Machine controller can match Nodes to Machines
func (r *KairosConfigReconciler) getProviderID(ctx context.Context, log logr.Logger, machine *clusterv1.Machine) string {
	if machine == nil {
		log.V(4).Info("Machine is nil, cannot get providerID")
		return ""
	}

	// First, check if Machine already has providerID set
	if machine.Spec.ProviderID != nil && *machine.Spec.ProviderID != "" {
		log.Info("Using providerID from Machine spec", "providerID", *machine.Spec.ProviderID, "machine", machine.Name)
		return *machine.Spec.ProviderID
	}

	// Try to get providerID from infrastructure reference (e.g., VSphereMachine)
	if machine.Spec.InfrastructureRef.Kind == "" {
		log.V(4).Info("Machine has no infrastructure reference, cannot get providerID", "machine", machine.Name)
		return ""
	}

	// For VSphere, get providerID from VSphereMachine spec
	if machine.Spec.InfrastructureRef.Kind == "VSphereMachine" {
		vsphereMachine := &unstructured.Unstructured{}
		vsphereMachine.SetGroupVersionKind(schema.GroupVersionKind{
			Group:   "infrastructure.cluster.x-k8s.io",
			Version: "v1beta1",
			Kind:    "VSphereMachine",
		})
		vsphereMachineKey := types.NamespacedName{
			Name:      machine.Spec.InfrastructureRef.Name,
			Namespace: machine.Spec.InfrastructureRef.Namespace,
		}

		if err := r.Get(ctx, vsphereMachineKey, vsphereMachine); err != nil {
			log.V(4).Info("Failed to get VSphereMachine for providerID", "machine", machine.Name, "vsphereMachine", vsphereMachineKey.Name, "error", err)
			return ""
		}

		// Try to get providerID from spec.providerID first (most reliable)
		if providerID, found, err := unstructured.NestedString(vsphereMachine.Object, "spec", "providerID"); err == nil && found && providerID != "" {
			log.V(4).Info("Found providerID in VSphereMachine spec", "providerID", providerID, "machine", machine.Name, "vsphereMachine", vsphereMachineKey.Name)
			return providerID
		}

		// Try to get VM UUID from status and construct providerID
		// This is set by CAPV after VM is provisioned
		if vmUUID, found, err := unstructured.NestedString(vsphereMachine.Object, "status", "vmUUID"); err == nil && found && vmUUID != "" {
			providerID := fmt.Sprintf("vsphere://%s", vmUUID)
			log.V(4).Info("Constructed providerID from VSphereMachine VM UUID", "providerID", providerID, "vmUUID", vmUUID, "machine", machine.Name, "vsphereMachine", vsphereMachineKey.Name)
			return providerID
		}

		// Check status.providerID as well (some CAPV versions set this)
		if providerID, found, err := unstructured.NestedString(vsphereMachine.Object, "status", "providerID"); err == nil && found && providerID != "" {
			log.V(4).Info("Found providerID in VSphereMachine status", "providerID", providerID, "machine", machine.Name, "vsphereMachine", vsphereMachineKey.Name)
			return providerID
		}

		log.Info("VSphereMachine found but no providerID or vmUUID available yet", "machine", machine.Name, "vsphereMachine", vsphereMachineKey.Name)
	}

	return ""
}
